{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text summarization: TextRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With enormous amount of data surrounding us, it is important to be able to extract the most important information from it. In this notebook, we focus on one such information extraction algorithm from text. \n",
    "\n",
    "Broadly speaking, there are two different approaches which one can take for summarizing text: extractive summarization where the summary of the document is a part of the document itself and abstractive summarization where the summary is not a part of the document and is generated by a learning model. \n",
    "\n",
    "Abstractive summarization is an extremely difficult problem and to date an area of cuntinued research. Some of the advancements in abstractive summarization using recurrant neural networks can be found in the works mentioned in [Quora](https://www.quora.com/Has-Deep-Learning-been-applied-to-automatic-text-summarization-successfully). \n",
    "\n",
    "In this work, we approach text summarization from an extractive viewpoint. The questions which we address are: \n",
    "   * Given a document, which are the most important lines in it?   \n",
    "   * Given a document, which are the most important key-words in it?  \n",
    "\n",
    "To answer these questions, we implement TextRank which is an algorithm that ranks text in a document based on the importance of the text. TextRank is analogous to Google's PageRank and was introduced by Mihalcea and Tarau in the paper [TextRank: Bringing Order into Texts](https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf).\n",
    "\n",
    "TextRank is an unsupervised learning algorithm and much simpler to implement as compared to abstractive summarization methods and yet yields good Recall-Oriented Understudy for Gisting Evaluation (ROGUE) scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "document = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_doc = \"Quantum mechanics is interesting. Quantum mechanics is weird. Hello, you there?\"\n",
    "document = simple_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For illustrative purpose, we will use the above simple_doc to show the steps involved in the implementation of TextRank. The following things should be noted about this document:\n",
    "   * It is clear that the third sentence is not something important. So, we expect that the third sentence should be ranked lowest by TextRank. \n",
    "   * It is not clear whether the first or the second sentence is more important. \n",
    "   * it is clear that \"quantum\" and \"mechanics\" are the most important words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quantum mechanics is interesting.', 'Quantum mechanics is weird.', 'Hello, you there?']\n"
     ]
    }
   ],
   "source": [
    "# From the document, extract the list sentences\n",
    "def get_sentences(doc):\n",
    "    sentence_tokenizer = PunktSentenceTokenizer()\n",
    "    return sentence_tokenizer.tokenize(doc)\n",
    "sentences = get_sentences(document)\n",
    "print sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'run', u'run', u'run']\n"
     ]
    }
   ],
   "source": [
    "# A callable class which stems the word to its root according to the rules defined in ProterStemmer\n",
    "class PorterTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.porter = PorterStemmer()\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return [self.porter.stem(word) for word in args[0].split()]\n",
    "print PorterTokenizer().__call__(\"run running runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "tfidf = TfidfVectorizer(preprocessor=None, \n",
    "                        stop_words=stopwords.words('english'),\n",
    "                        tokenizer=PorterTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
